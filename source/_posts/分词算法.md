---
title: 文本预处理-分词算法
date: 2025-02-20
tags: [NLP, 算法]
categories: 技术
toc: true
---

# 文本预处理-分词算法

行文逻辑：分词算法=>Byte-Pair Encoding

**to work with a large amount of text data readily available on the internet, we need manipulation and cleaning of text which we commonly call text pre-processing in NLP.**[1]

当前tokenization主要分为：word，sub-word， charlevel 三个类型

主流的sub-word tokenization方法有：WordPiece, Byte-Pair Encoding (BPE), Unigram, SentencePiece.

# 一、The Difference between Word ...

这个部分会叙述一下背景知识，同时介绍不同粒度的分词算法的差异。

**Tokenization** 简单来说就是将短语，句子，段落等文本数据切分成更小的单元（称为token）。
